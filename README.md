# Face-Controlled-Interface
Takes inputs from face of the user to interact with user interface on computer. Uses MediaPipe to capture facial positions as inputs, uses PyAutoGUI to automate mouse and keyboard functions based on detected motions.

Uses movement of nose to control cursor, open mouth to left click, and left eye wink to bring up and down keyboard.

Note: Works optimally with python-3.8.9.
